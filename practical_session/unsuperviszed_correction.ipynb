{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentisage non-supervisé:\n",
    "\n",
    "Le but de ce TP est d'implémenter et tester les algorithmes vues en classes.\n",
    "\n",
    "## Clustering hiérarchique:\n",
    "\n",
    "On commence par implémenter le premier algorithme. Le bout de code suivant contient des fonctions qui vont être utilisées dans le reste du TP.\n",
    "\n",
    "1.\n",
    "Exécuter la cellule suivante.\n",
    "\n",
    "2.\n",
    "Lire les docstrings pour comprendre comment utiliser le fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_points(points, ax, color):\n",
    "    \"\"\"\n",
    "        Plots points.\n",
    "        :param points: the points to plot\n",
    "        :type points: iterable\n",
    "        :param ax: the axis to plot in\n",
    "        :type ax: matplotlib.axis\n",
    "        :param color: the plotted points color\n",
    "        :type color: str\n",
    "    \"\"\"\n",
    "    ax.scatter(points[:, 0], points[:, 1], c=color)\n",
    "\n",
    "    \n",
    "def plot_dataset(X, Y, ax, **parameters):\n",
    "    \"\"\"\n",
    "        Plots the dataset.\n",
    "        :param X: the points to plot\n",
    "        :type X: np.array\n",
    "        :param Y: the points classes\n",
    "        :type Y: np.array\n",
    "        :param ax: the axis to plot in\n",
    "        :type ax: matplotlib.axis\n",
    "        :param colors: the plotted points colors depending on the class\n",
    "        :type colors: iterable\n",
    "    \"\"\"\n",
    "    for x, color in zip([X[Y==y] for y in set(Y)], parameters['colors']):\n",
    "        plot_points(x, ax, color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On génère un jeu de donner simple pour tester les algorithmes à implémenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "K_gt = 3\n",
    "X, Y = sklearn.datasets.make_blobs(n_samples=100, centers=K_gt, random_state=0, cluster_std=.6)\n",
    "\n",
    "# Plotting the ground truth\n",
    "f, ax = plt.subplots(1, 1)\n",
    "plot_dataset(X, Y, ax, colors=plt.cm.rainbow(np.linspace(0, 1, K_gt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On présente, ci-dessous, les métrique à utiliser pour comparer les ensembles. Lancer ce bout de code pour comprendre comment utiliser ces fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(A, B, metric):\n",
    "    \"\"\"\n",
    "        Compute the list of all distances between elements from sets A and B based on the `metric' distance.\n",
    "        :param A: the left hand operand\n",
    "        :type A: set\n",
    "        :param B: the right hand operand\n",
    "        :type B: set\n",
    "        :param metric: the distance to be used\n",
    "        :type metric: callable\n",
    "        :return: the distance\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    return [\n",
    "            metric(a, b)\n",
    "            for a in A\n",
    "            for b in B\n",
    "        ]\n",
    "    \n",
    "\n",
    "def minimum_metric(metric):\n",
    "    \"\"\"\n",
    "        Compute the minimum distance between sets A and B based on the `metric' distance.\n",
    "        :param metric: the distance to be used\n",
    "        :type metric: callable\n",
    "        :return: the distance\n",
    "        :rtype: callable\n",
    "    \"\"\"\n",
    "    return lambda A, B: min(distances(A, B, metric))\n",
    "\n",
    "\n",
    "def maximum_metric(metric):\n",
    "    \"\"\"\n",
    "        Compute the maximum distance between sets A and B based on the `metric' distance.\n",
    "        :param metric: the distance to be used\n",
    "        :type metric: callable\n",
    "        :return: the distance\n",
    "        :rtype: callable\n",
    "    \"\"\"\n",
    "    return lambda A, B: max(distances(A, B, metric))\n",
    "\n",
    "\n",
    "def mean_metric(metric):\n",
    "    \"\"\"\n",
    "        Compute the mean distance between sets A and B based on the `metric' distance.\n",
    "        :param metric: the distance to be used\n",
    "        :type metric: callable\n",
    "        :return: the distance\n",
    "        :rtype: callable\n",
    "    \"\"\"\n",
    "    return lambda A, B: sum(distances(A, B, metric)) / (len(A) * len(B))\n",
    "\n",
    "\n",
    "def array2tuples(feats):\n",
    "    \"\"\"\n",
    "        Transform an attributes matrix to a list of tuples which is hashable. This may be handy when it is necessary to have hashable data.\n",
    "        :param feats: the feature matrix where lines are instances and columns are dimensions\n",
    "        :type feats: np.array\n",
    "        :return: the list of tuple representation.\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    return [tuple(x) for x in feats]\n",
    "\n",
    "\n",
    "def tuples2array(tuples):\n",
    "    \"\"\"\n",
    "        Transform a list of tuples to an attributes matrix.\n",
    "        :param tuples: the list of tuple representations\n",
    "        :type tuples: np.array\n",
    "        :return: feature matrix where lines are instances and columns are dimensions\n",
    "        :rtype: np.array\n",
    "    \"\"\"\n",
    "    return np.array([list(x) for x in tuples])\n",
    "\n",
    "\n",
    "\n",
    "print('Example:')\n",
    "A = set(array2tuples(X[Y==0]))\n",
    "print('A = ', A)\n",
    "B = set(array2tuples(X[Y==1]))\n",
    "print('B = ', B)\n",
    "euclidian = lambda x, y: np.linalg.norm(np.array(x) - np.array(y))\n",
    "print('\\nOn utilise la distance Euclidienne: ', euclidian)\n",
    "print('La distance minimale entre A et B est:', minimum_metric(euclidian)(A, B))\n",
    "print('La distance maximale entre A et B est:', maximum_metric(euclidian)(A, B))\n",
    "print('La distance moyenne entre A et B est:', mean_metric(euclidian)(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "Implémenter les fonctions `minimal_couples`, `prune_minimizers` et `update_clustering` de clustering hiérarchique ascendant en complétant les fonctions présentées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools, operator\n",
    "\n",
    "\n",
    "def minimal_couples(P, group_metric):\n",
    "    \"\"\"\n",
    "        Find the partition index couples that minimizes the `group_metric' over all couples from the partition S.\n",
    "        :param P: the list of all sets forming the features partition.\n",
    "        :type P: list\n",
    "        :param group_metric: the metric to compare partitions\n",
    "        :type group_metric: callable\n",
    "        :return: the list of couples (s, l) minimizing (s, l) --> group_metric(P[s], P[l]).\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    # Hint: Use built-in python minimum function `min' on a list of tuples containing the couple (s, l) and the value group_metric(P[s], P[l])\n",
    "    \n",
    "    # Map all non redundant partion indexe couples and distances\n",
    "    index_couple_distance_map = [\n",
    "        (s, l, group_metric(p, q))\n",
    "        for (s, p) in enumerate(P) # each set `p' in `P' has index `s'\n",
    "        for (l, q) in enumerate(P)\n",
    "        if s < l # For non redundancy \n",
    "    ]\n",
    "    _, _, min_distance = min(\n",
    "        index_couple_distance_map,\n",
    "        key=operator.itemgetter(-1) # Function that returns the last element of an iterable: That is what will be sorted\n",
    "    )\n",
    "    return [\n",
    "        (s, l) \n",
    "        for s, l, distance in index_couple_distance_map\n",
    "        if distance == min_distance\n",
    "    ]\n",
    "\n",
    "\n",
    "def prune_minimizers(couples):\n",
    "    \"\"\"\n",
    "        Prune couples into a list of partition indexes to group.\n",
    "        :param group_metric: the metric to compare partitions\n",
    "        :type group_metric: callable\n",
    "        :return: the list of sets of pruned couples.\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    # Hint: Use sets for unicity\n",
    "    return [\n",
    "        set.union(\n",
    "            *[\n",
    "                set(c_k)\n",
    "                for c_k in couples\n",
    "                if bool(set(c_k).intersection(set(c_i))) # Keep only c_k and c_i have a common element\n",
    "            ]\n",
    "        )\n",
    "        for c_i in couples\n",
    "    ]\n",
    "\n",
    "\n",
    "def update_clustering(indexes_to_cluster, P):\n",
    "    \"\"\"\n",
    "        Updates the partition based on the indexes of partitions to cluster.\n",
    "        :param indexes_to_cluster: list of indexes of partition to cluster\n",
    "        :type indexes_to_cluster: list\n",
    "        :param P: the list of all sets forming the features partition.\n",
    "        :type P: list\n",
    "        :return: the new partition\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    # Group sets from partition `P' with indexes `indexes_to_cluster'\n",
    "    Q = [\n",
    "        set.union(\n",
    "            *[\n",
    "                P[index]\n",
    "                for index in e_i\n",
    "            ] # All sets to fuse\n",
    "        )\n",
    "        for e_i in indexes_to_cluster\n",
    "    ]\n",
    "    # Keep the rest unchanged\n",
    "    Q += [\n",
    "        P[index]\n",
    "        for index in set(range(len(P))) - set.union(*indexes_to_cluster)\n",
    "    ]\n",
    "    return Q\n",
    "    \n",
    "\n",
    "def hierarchical_clustering(X, group_metric=mean_metric(euclidian), T=100, K=3):\n",
    "    \"\"\"\n",
    "        The hierarchical clustering algorithm.\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param group_metric: the metric to compare partitions\n",
    "        :type group_metric: callable\n",
    "        :param T: maximal iterations\n",
    "        :type T: int\n",
    "        :param K: wanted number of clusters\n",
    "        :type K: int\n",
    "        :return: The list of partitions per iteration\n",
    "        :type: list\n",
    "    \"\"\"\n",
    "    initial_partition = [set([x]) for x in array2tuples(X)]\n",
    "    cl = len(initial_partition)\n",
    "    S = [None] * (T + 1) # Do not append: it is very slow\n",
    "    S[0] = initial_partition\n",
    "    t = 0\n",
    "    while t < T and cl > K:\n",
    "        t += 1\n",
    "        couples = minimal_couples(S[t-1], group_metric) # Minimal couples\n",
    "        indexes_to_cluster = prune_minimizers(couples) # Minimal indexes grouped\n",
    "        S[t] = update_clustering(indexes_to_cluster, S[t-1])\n",
    "        cl = len(S[t])\n",
    "        print('Iteration t =', t, '-->', cl, 'clusters')\n",
    "    return S[:(t+1)] # return all not None partions\n",
    "\n",
    "S = hierarchical_clustering(X, K=K_gt)\n",
    "\n",
    "# Plotting the result\n",
    "clusters = np.array(\n",
    "    functools.reduce(\n",
    "        operator.add,\n",
    "        [[cls] * len(set_cls) for (cls, set_cls) in enumerate(S[-1])]\n",
    "    )\n",
    ")\n",
    "H = np.concatenate([tuples2array(x) for x in S[-1]])\n",
    "f, ax = plt.subplots(1, 1)\n",
    "plot_dataset(H, clusters, ax, colors=plt.cm.rainbow(np.linspace(0,1,len(S[-1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "Comparer les résultats à la vérité terrain.\n",
    "\n",
    "4.\n",
    "Essayer plusieurs valeurs de K et de deviation standard de données d'entrées. Commenter les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-moyennes:\n",
    "\n",
    "5.\n",
    "Compléter les fonctions suivantes pour implémenter l'algorithme K-moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def read_image(filename):\n",
    "    return skimage.io.imread(filename)\n",
    "\n",
    "\n",
    "def sample(X, K):\n",
    "    \"\"\"\n",
    "        Sample `K' instances from X.\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param K: wanted number of clusters\n",
    "        :type K: int\n",
    "        :return: The map of clusters and their sampled index\n",
    "        :type: dict\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "        enumerate(\n",
    "            random.sample(\n",
    "                range(len(X)),\n",
    "                K\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def diff(centers, t, metric=euclidian):\n",
    "    \"\"\"\n",
    "        Compute the change in centers at time t.\n",
    "        :param centers: the centers \n",
    "        :type centers: np.array\n",
    "        :param t: the iteration\n",
    "        :type t: int\n",
    "        :return: The differences per cluster in an array\n",
    "        :type: np.array\n",
    "    \"\"\"\n",
    "    return sum(\n",
    "        [\n",
    "            metric(after, before)\n",
    "            for after, before\n",
    "            in zip(centers[t], centers[t-1])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def assign(X, mus, metric=euclidian):\n",
    "    \"\"\"\n",
    "        Assign each instance the cluster of the closest center in mus.\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param mus: the list of centers\n",
    "        :type mus: list\n",
    "        :return: The map of clusters and correponding instance indices\n",
    "        :type: dict\n",
    "    \"\"\"\n",
    "    # Compute the closest cluster for each instance\n",
    "    index_cluster_map = {\n",
    "        index: \n",
    "        min(\n",
    "            [\n",
    "                (k, metric(x, mu))\n",
    "                for k, mu in enumerate(mus)\n",
    "            ],\n",
    "            key=operator.itemgetter(-1) # chooses the last element: the distance between `x' and `mu' to minimize\n",
    "        )[0] # the index of the closest center\n",
    "        for index, x in enumerate(X)\n",
    "    }\n",
    "    return {\n",
    "        k: [\n",
    "            index\n",
    "            for index, k_index in index_cluster_map.items()\n",
    "            if k == k_index\n",
    "        ] # To fill: This is the list of indices of all instances in cluster k\n",
    "        for k, mu in enumerate(mus)\n",
    "    } \n",
    "\n",
    "\n",
    "def update_centers(indices_map, X):\n",
    "    \"\"\"\n",
    "        Update partition centers\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param indices_map: map of cluster indices\n",
    "        :type indices_map: dict\n",
    "        :return: partion centers\n",
    "        :type: list\n",
    "    \"\"\"\n",
    "    return [\n",
    "        np.mean(X[indices_map[k]], axis=0)\n",
    "        for k in sorted(indices_map)\n",
    "    ]\n",
    "\n",
    "\n",
    "def compute_intravariance(X, mus, indices_map, metric=euclidian):\n",
    "    \"\"\"\n",
    "        Compute Iw for the partition.\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param mus: the list of centers\n",
    "        :type mus: list\n",
    "        :param indices_map: map of cluster indices\n",
    "        :type indices_map: dict\n",
    "        :return: Inertia intraclasse\n",
    "        :type: float\n",
    "    \"\"\"\n",
    "    return sum(\n",
    "        [\n",
    "            sum(\n",
    "                [\n",
    "                    pow(metric(x, mu), 2)\n",
    "                    for x in X[indices_map[k]]\n",
    "                ]\n",
    "            )\n",
    "            for k, mu in enumerate(mus)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "def k_means(X, metric=euclidian, T=100, K=3, epsilon=0):\n",
    "    \"\"\"\n",
    "        The hierarchical clustering algorithm.\n",
    "        :param X: the feature matrix\n",
    "        :type X: np.array\n",
    "        :param metric: the metric to apply on the attribute space\n",
    "        :type metric: callable\n",
    "        :param T: maximal iterations\n",
    "        :type T: int\n",
    "        :param K: wanted number of clusters\n",
    "        :type K: int\n",
    "        :return: couple of map of clusters and corresponding instances and the values taken by Iw\n",
    "        :type: tuple\n",
    "    \"\"\"\n",
    "    indices_map = sample(X, K)\n",
    "    t = 0\n",
    "    centers = [None] * (T + 1)\n",
    "    Iw = [None] * (T + 1)\n",
    "    centers[0] = list(X[list(indices_map.values())])\n",
    "    Iw[0] = float('Inf')\n",
    "    while True: # Emulates do ... while in python\n",
    "        t += 1\n",
    "        indices_map = assign(X, centers[t-1], metric)\n",
    "        centers[t] = update_centers(indices_map, X)\n",
    "        Iw[t] = compute_intravariance(X, centers[t], indices_map, metric)\n",
    "        if t >= T or diff(centers, t, metric) <= epsilon:\n",
    "            break\n",
    "    centers = [mus for mus in centers if mus is not None]\n",
    "    Iw = Iw[:len(centers)]\n",
    "    return (\n",
    "        {k: X[[indices]] for k, indices in indices_map.items()},\n",
    "        Iw[:(t + 1)],\n",
    "        centers[:(t + 1)]\n",
    "    )\n",
    "\n",
    "cluster_maps, Iw, centers = k_means(X, K=K_gt)\n",
    "print('The minimum intravariance inertia is:', Iw[-1])\n",
    "\n",
    "# Plotting the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(20)\n",
    "\n",
    "clusters = np.array(\n",
    "    np.array(\n",
    "        functools.reduce(\n",
    "            operator.add,\n",
    "            [[k] * set_k.shape[0] for (k, set_k) in cluster_maps.items()]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "M = np.concatenate(\n",
    "    [\n",
    "        set_k\n",
    "        for (k, set_k) in cluster_maps.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_dataset(M, clusters, ax1, colors=plt.cm.rainbow(np.linspace(0,1,len(S[-1]))))\n",
    "\n",
    "# plot Iw\n",
    "ax2.plot(range(len(Iw)), Iw)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\n",
    "\n",
    "    a. Comparer le résultat de K-moyenne avec différentes initialisations. Commenter.\n",
    "\n",
    "    b. Commenter la courbe d'inertie avec différentes initialisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\n",
    "Essayer plusieurs valeurs de K et de deviation standard de données d'entrées. Commenter les résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
